{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import random, os\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_ARR = [16,32,64,128] # [64,128,256,512]\n",
    "\n",
    "# for loading encoder and decoder:\n",
    "LOAD_PATH_ENC = \"checkpoints/encoder/\"          # path to where encoder is\n",
    "ENC_NAME = \"encoder_model\"              # name of saved encoder\n",
    "\n",
    "LOAD_PATH_DEC = \"checkpoints/decoder/\"            # path to where decoder is\n",
    "DEC_NAME = \"decoder_model\"            # name of saved decoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, FEATURE_ARR[0], 5, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(FEATURE_ARR[0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(FEATURE_ARR[0], FEATURE_ARR[1], 5, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(FEATURE_ARR[1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(FEATURE_ARR[1], FEATURE_ARR[2], 5, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(FEATURE_ARR[2]),\n",
    "            nn.ReLU(True),     \n",
    "            nn.Conv2d(FEATURE_ARR[2], FEATURE_ARR[3], 7, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(FEATURE_ARR[3]),\n",
    "            nn.ReLU(True),  \n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(FEATURE_ARR[3], 1, 1))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(FEATURE_ARR[3], FEATURE_ARR[2], 7, \n",
    "            stride=2, padding=0, output_padding=0),\n",
    "            nn.BatchNorm2d(FEATURE_ARR[2]),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(FEATURE_ARR[2], FEATURE_ARR[1], 5, \n",
    "            stride=2, padding=1, output_padding=0),\n",
    "            nn.BatchNorm2d(FEATURE_ARR[1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(FEATURE_ARR[1], FEATURE_ARR[0], 5, \n",
    "            stride=2, padding=1, output_padding=0),\n",
    "            nn.BatchNorm2d(FEATURE_ARR[0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(FEATURE_ARR[0], 1, 5, \n",
    "            stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ENCODER:\n",
    "checkpoint = torch.load(f'{LOAD_PATH_ENC}{ENC_NAME}.tar')\n",
    "encoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "# LOAD LSTM:\n",
    "checkpoint = torch.load(f'{LOAD_PATH_DEC}{DEC_NAME}.tar')\n",
    "decoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "decoder.to(device)\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using encoder/decoder on loaded map\n",
    "NUM_MAPS = 20\n",
    "DIR_NAME = \"env/100000_maps/\"\n",
    "\n",
    "# setting up figure:\n",
    "fig = plt.figure(figsize=(10,75))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "plot_num = 1\n",
    "for i in range(NUM_MAPS):\n",
    "\n",
    "    # loading map:\n",
    "    flat_map = np.loadtxt(f\"{DIR_NAME}map_{i}.txt\") \n",
    "    map = torch.tensor(np.asarray(flat_map, dtype=int).reshape(64, 64)).to(device, dtype=torch.float)     # unflatten the map from the file\n",
    "\n",
    "    # encoding and decoding map:\n",
    "    map_4d = map.unsqueeze(0).unsqueeze(0)\n",
    "    encoded_map = encoder(map_4d)\n",
    "    decoded_map = decoder(encoded_map)\n",
    "    new_map_2d = decoded_map.squeeze()\n",
    "\n",
    "    # plot og map:\n",
    "    sub = fig.add_subplot(NUM_MAPS,2,plot_num)\n",
    "    plt.imshow(map.cpu(), cmap='gray')\n",
    "    if plot_num < 3:\n",
    "        plt.title('Original Map')\n",
    "    plot_num += 1\n",
    "\n",
    "    # plot encoded and decoded map:\n",
    "    sub = fig.add_subplot(NUM_MAPS,2,plot_num)\n",
    "    plt.imshow(new_map_2d.cpu().detach().numpy(), cmap='gray')\n",
    "    if plot_num < 3:\n",
    "        plt.title('Encoded and Decoded Map')\n",
    "    plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_MAPS):\n",
    "\n",
    "    # loading map:\n",
    "    flat_map = np.loadtxt(f\"{DIR_NAME}map_{i}.txt\") \n",
    "    map = torch.tensor(np.asarray(flat_map, dtype=int).reshape(64, 64)).to(device, dtype=torch.float)     # unflatten the map from the file\n",
    "\n",
    "    # encoding and decoding map:\n",
    "    map_4d = map.unsqueeze(0).unsqueeze(0)\n",
    "    encoded_map = encoder(map_4d)\n",
    "    decoded_map = decoder(encoded_map)\n",
    "    new_map_2d = decoded_map.squeeze()\n",
    "\n",
    "    # setting up figure:\n",
    "    fig = plt.figure(figsize=(10,25))\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    # plot og map:\n",
    "    sub = fig.add_subplot(121)\n",
    "    plt.imshow(map.cpu(), cmap='gray')\n",
    "    plt.title('Original Map')\n",
    "\n",
    "    # plot encoded and decoded map:\n",
    "    sub = fig.add_subplot(122)\n",
    "    plt.imshow(new_map_2d.cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title('Encoded and Decoded Map')\n",
    "\n",
    "    plt.savefig(f\"outputs/map_{i}.png\", facecolor=fig.get_facecolor(), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
