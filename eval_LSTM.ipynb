{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os, random, math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from lstm_class import LSTM_Single_Layer            # *!*!*!*!* ensure correct LSTM structure is loaded !*!**!*!*!\n",
    "from path_functions import check_if_avoids_obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS:\n",
    "# for loading encoder and lstm:\n",
    "LOAD_PATH_ENC = \"checkpoints/encoder/\"          # path to where encoder is\n",
    "ENC_NAME = \"pretty_decent_encoder\"              # name of saved encoder\n",
    "checkpoint_enc = torch.load(f'{LOAD_PATH_ENC}{ENC_NAME}.tar')\n",
    "\n",
    "LOAD_PATH_LSTM = \"checkpoints/lstm/\"            # path to where lstm is\n",
    "LSTM_NAME = \"trained_on_60000_paths\"            # name of saved lstm\n",
    "checkpoint_lstm = torch.load(f'{LOAD_PATH_LSTM}{LSTM_NAME}.tar')\n",
    "\n",
    "# for loading dataset:\n",
    "DATASET = 'random_20_density/'\n",
    "MAP_SHAPE = (64,64)\n",
    "NUM_TRAIN_PATHS = 10\n",
    "NUM_EVAL_PATHS = 10\n",
    "NUM_GENERATED_POINTS = 30\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathsDataset(torch.utils.data.Dataset):\n",
    "    # init the dataset, shape = L x W\n",
    "    def __init__(self, gen_dir, transform=None, shape = (100,100), device='cpu', stop_after=500):\n",
    "        self.device = device\n",
    "        self.maps_and_paths = []\n",
    "\n",
    "        num_maps = 0\n",
    "        for directory in tqdm(os.listdir(gen_dir)):\n",
    "            num_maps += 1\n",
    "            dir_path = os.path.join(gen_dir, directory)\n",
    "            sequence = []\n",
    "\n",
    "            # open map file:\n",
    "            with open(f\"{dir_path}/{directory}.txt\", 'r') as f:\n",
    "                self.flat_map = np.loadtxt(f)\n",
    "                self.map = np.asarray(self.flat_map, dtype=np.float32).reshape(shape[0],shape[1])\n",
    "\n",
    "            # add map to sequence array:\n",
    "            sequence.append(torch.tensor(self.map))\n",
    "\n",
    "            path_dir = f\"{dir_path}/paths/\"\n",
    "            num_paths = 0\n",
    "            for filename in os.listdir(path_dir):\n",
    "                num_paths += 1\n",
    "                with open(os.path.join(path_dir, filename), 'r') as f: # open in readonly mode\n",
    "                    path_points_list = [] # a list to hold each point in a path\n",
    "                    self.flat_path = np.loadtxt(f) # load in the flat path from file\n",
    "                    self.path = np.asarray(self.flat_path, dtype=np.float32).reshape(len(self.flat_path)//2,2) #unflatten the path from the file\n",
    "                    for point in self.path:\n",
    "                        x = point[0]\n",
    "                        y = point[1]\n",
    "                        this_point = [x, y]\n",
    "                        path_points_list.append(this_point)\n",
    "                        \n",
    "                sequence.append(torch.tensor(path_points_list, dtype=torch.float)[:, :])\n",
    "                \n",
    "            self.maps_and_paths.append(sequence)\n",
    "\n",
    "            if num_maps == stop_after:\n",
    "                break\n",
    "        \n",
    "        self.transform = transform\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.maps_and_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.maps_and_paths[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE ENCODER STRUCTURE:\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 5, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 5, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),     \n",
    "            nn.Conv2d(64, 128, 7, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),  \n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE ENCODER INSTANCE:\n",
    "encoder = Encoder()\n",
    "\n",
    "# CREATE LSTM INSTANCE:\n",
    "rnn = LSTM_Single_Layer(device=device, dropout=checkpoint_lstm['dropout'], dropout_p=checkpoint_lstm['dropout_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ENCODER:\n",
    "encoder.load_state_dict(checkpoint_enc['model_state_dict'])\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "# LOAD LSTM:\n",
    "rnn.load_state_dict(checkpoint_lstm['model_state_dict'])\n",
    "rnn.to(device)\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PATHS:\n",
    "train_dataset = PathsDataset(gen_dir = f\"./env/{DATASET}/train\", shape = MAP_SHAPE, transform=None, device=device, stop_after=1000)\n",
    "eval_dataset = PathsDataset(gen_dir = f\"./env/{DATASET}/eval\", shape = MAP_SHAPE, transform=None, device=device, stop_after=1000)\n",
    "train_len = len(train_dataset)\n",
    "eval_len = len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING LSTM PATHS FROM TRAIN DATA:\n",
    "\n",
    "generated_train_paths = []\n",
    "random_train_vals = []\n",
    "valid_train_paths = 0\n",
    "\n",
    "for i in range(NUM_TRAIN_PATHS):\n",
    "    # choose random map:\n",
    "    map_num = random.randint(0, train_len-1)\n",
    "    map = train_dataset[map_num][0].to(device)\n",
    "    encoded_map = encoder(map.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "    # choose random path:\n",
    "    path_num = random.randint(1, len(train_dataset[map_num])-1)\n",
    "    path = train_dataset[map_num][path_num]\n",
    "\n",
    "    # generate lstm path:\n",
    "    start_point = path[0].to(device)\n",
    "    goal_point = path[len(path)-1].to(device)\n",
    "    generated_pts = []\n",
    "    with torch.no_grad():\n",
    "        # add start point:\n",
    "        generated_pts.append(start_point.cpu().detach().numpy().tolist())\n",
    "        prev_pred = start_point\n",
    "\n",
    "        # predict and add other points:\n",
    "        for i in range(NUM_GENERATED_POINTS):\n",
    "            pred = rnn(goal_point, prev_pred, encoded_map).squeeze()\n",
    "            prev_pred = pred\n",
    "            generated_pts.append(pred.cpu().detach().numpy().tolist())\n",
    "\n",
    "    generated_train_paths.append(generated_pts)\n",
    "    random_train_vals.append([map_num, path_num])\n",
    "\n",
    "    # checking if valid path:\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for x,y in generated_pts:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    valid_train_paths += check_if_avoids_obstacles(xs, ys, map.cpu().detach().numpy(), check_dis=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING FIGURE FOR TRAIN DATA:\n",
    "\n",
    "print(f\"Percentage of successful paths: {valid_train_paths/NUM_TRAIN_PATHS*100}%\")\n",
    "print(f\"Num of maps: {len(train_dataset)}\")\n",
    "print(f\"Total num of paths: {len(train_dataset)*(len(train_dataset[0])-1)}\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,30))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "col_title = True\n",
    "for i in range(NUM_TRAIN_PATHS):\n",
    "\n",
    "    map_idx = random_train_vals[i][0]\n",
    "    path_idx = random_train_vals[i][1]\n",
    "\n",
    "    map = train_dataset[map_idx][0]\n",
    "    start_point = train_dataset[map_idx][path_idx][0]\n",
    "    goal_point = train_dataset[map_idx][path_idx][len(train_dataset[map_idx][path_idx])-1]\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for x,y in generated_train_paths[i]:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    sub = fig.add_subplot(NUM_TRAIN_PATHS,4,i*4+1)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(map.cpu())\n",
    "    if col_title:\n",
    "        plt.title('Obstacles')\n",
    "\n",
    "    sub = fig.add_subplot(NUM_TRAIN_PATHS,4,i*4+2)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(map.cpu())\n",
    "    # plot truth path\n",
    "    plt.plot(train_dataset[map_idx][path_idx][:,0], train_dataset[map_idx][path_idx][:,1], color='orange')\n",
    "    plt.scatter(goal_point[0], goal_point[1], color=\"r\")\n",
    "    plt.scatter(start_point[0], start_point[1], color=\"g\")\n",
    "    if col_title:\n",
    "        plt.title('RRT Star Paths')\n",
    "\n",
    "    sub = fig.add_subplot(NUM_TRAIN_PATHS,4,i*4+3)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(map.cpu())\n",
    "    plt.plot(xs, ys, color='aqua', label = \"predicted\")\n",
    "    plt.scatter(goal_point[0], goal_point[1], color=\"r\")\n",
    "    plt.scatter(start_point[0], start_point[1], color=\"g\")\n",
    "    if col_title:\n",
    "        plt.title('LSTM Paths')\n",
    "\n",
    "    col_title = False\n",
    "\n",
    "plt.savefig(\"train_output.png\", facecolor=fig.get_facecolor(), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING LSTM PATHS FROM EVAL DATA:\n",
    "\n",
    "generated_eval_paths = []\n",
    "random_eval_vals = []\n",
    "valid_eval_paths = 0\n",
    "\n",
    "for i in range(NUM_EVAL_PATHS):\n",
    "    # choose random map:\n",
    "    map_num = random.randint(0, eval_len-1)\n",
    "    map = eval_dataset[map_num][0].to(device)\n",
    "    encoded_map = encoder(map.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "    # choose random path:\n",
    "    path_num = random.randint(1, len(eval_dataset[map_num])-1)\n",
    "    path = eval_dataset[map_num][path_num]\n",
    "\n",
    "    # generate lstm path:\n",
    "    start_point = path[0].to(device)\n",
    "    goal_point = path[len(path)-1].to(device)\n",
    "    generated_pts = []\n",
    "    with torch.no_grad():\n",
    "        # add start point:\n",
    "        generated_pts.append(start_point.cpu().detach().numpy().tolist())\n",
    "        prev_pred = start_point\n",
    "\n",
    "        # predict and add other points:\n",
    "        for i in range(NUM_GENERATED_POINTS):\n",
    "            pred = rnn(goal_point, prev_pred, encoded_map).squeeze()\n",
    "            prev_pred = pred\n",
    "            generated_pts.append(pred.cpu().detach().numpy().tolist())\n",
    "\n",
    "    generated_eval_paths.append(generated_pts)\n",
    "    random_eval_vals.append([map_num, path_num])\n",
    "\n",
    "    # checking if valid path:\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for x,y in generated_pts:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    valid_eval_paths += check_if_avoids_obstacles(xs, ys, map.cpu().detach().numpy(), check_dis=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING FIGURE FOR EVAL DATA:\n",
    "\n",
    "print(f\"Percentage of successful paths: {valid_eval_paths/NUM_EVAL_PATHS*100}%\")\n",
    "print(f\"Num of maps: {len(train_dataset)}\")\n",
    "print(f\"Total num of paths: {len(train_dataset)*(len(train_dataset[0])-1)}\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,30))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "col_title = True\n",
    "for i in range(NUM_EVAL_PATHS):\n",
    "\n",
    "    map_idx = random_eval_vals[i][0]\n",
    "    path_idx = random_eval_vals[i][1]\n",
    "\n",
    "    map = eval_dataset[map_idx][0]\n",
    "    start_point = eval_dataset[map_idx][path_idx][0]\n",
    "    goal_point = eval_dataset[map_idx][path_idx][len(eval_dataset[map_idx][path_idx])-1]\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for x,y in generated_eval_paths[i]:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    sub = fig.add_subplot(NUM_EVAL_PATHS,4,i*4+1)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(map.cpu())\n",
    "    if col_title:\n",
    "        plt.title('Obstacles')\n",
    "\n",
    "    sub = fig.add_subplot(NUM_EVAL_PATHS,4,i*4+2)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(map.cpu())\n",
    "    # plot truth path\n",
    "    plt.plot(eval_dataset[map_idx][path_idx][:,0], eval_dataset[map_idx][path_idx][:,1], color='orange')\n",
    "    plt.scatter(goal_point[0], goal_point[1], color=\"r\")\n",
    "    plt.scatter(start_point[0], start_point[1], color=\"g\")\n",
    "    if col_title:\n",
    "        plt.title('RRT Star Paths')\n",
    "\n",
    "    sub = fig.add_subplot(NUM_EVAL_PATHS,4,i*4+3)\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    plt.imshow(map.cpu())\n",
    "    plt.plot(xs, ys, color='aqua', label = \"predicted\")\n",
    "    plt.scatter(goal_point[0], goal_point[1], color=\"r\")\n",
    "    plt.scatter(start_point[0], start_point[1], color=\"g\")\n",
    "    if col_title:\n",
    "        plt.title('LSTM Paths')\n",
    "\n",
    "    col_title = False\n",
    "\n",
    "plt.savefig(\"eval_output.png\", facecolor=fig.get_facecolor(), bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
